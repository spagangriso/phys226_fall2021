{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Fitting a Signal in the Presence of Background (40 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning objectives\n",
    "In this question you will:\n",
    "\n",
    "- Gain experience in performing $\\chi^2$ fits to histogrammed data; explore how the statistical significance of a signal depends on the number of signal events and the signal-to-background ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "source": [
    "Physicists often fit for signals in the presence of background. Compared to the previous exercise, we now explore the situation where it is not possible to take data separately in background-only mode. In such cases, the significance of the measured signal depends not only on the number of signal events but also on the amount of background *and* our ability to statistically separate the two.  \n",
    "\n",
    "In this problem, we will explore fitting signal and background for a very simple case:  The signal is a Gaussian peak centered at $x=10$ with a width $\\sigma=1$ and the background is uniformly distributed between $x=0$ and $x=20$.  \n",
    "\n",
    "The code below generates fake data, allowing you to change both the number of events in the signal and the ratio of signal-to-background.  To make sure that our definition of background does not depend on the fit range, the code below defines the signal-to-background ratio as the ratio number of signal events to the number of background events in a $\\pm 2 \\sigma$ window around the signal peak.  Here is the code you will use to generate the fake data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "outputs": [],
   "source": [
    "# Write import math\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def makeData( SignalToBackground, nSigEvents, seed=12345):\n",
    "    \"\"\"Generates a dataset consisting of nEvents some of which are signal (a Gaussian with a width of 1 centered\n",
    "    at x=5) and the rest of which is background\n",
    "    Definition of SignalToBackground:  The ratio of the number of signal events within 2 sigma of the peak to the number\n",
    "    of background events in that same x-range  (this definition is just a choice)\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "     SignalToBackground : float\n",
    "     Ratio of the number of signal events within 2 sigma of the peak to the number\n",
    "    of background events in that same x-range  (this definition is just a choice) \n",
    "      \n",
    "    nSigEvents : int\n",
    "      total number of signal events generated (NOT the number in +- 2 sigma)\n",
    "      \n",
    "    seed : int\n",
    "      seed for the random number generator\n",
    "      \n",
    "    Returns\n",
    "    =======\n",
    "    data : array\n",
    "      the measurements of x\n",
    "    \"\"\"\n",
    "    fracOutsideTwoSigma = 4.55e-2\n",
    "    # 1-fracOutsideTwoSigma is the fraction of the Signal Events within +-2 sigma\n",
    "    # To get the total number of background events, find the number in +-2 sigma\n",
    "    # which is 4 units of x and then since the background is flat from 0 to 20\n",
    "    # multiply by 20/4=5\n",
    "    \n",
    "    nBackground = 5*nSigEvents*(1-fracOutsideTwoSigma)/SignalToBackground\n",
    "    nEvents = nSigEvents+nBackground\n",
    "    fSig = nSigEvents/nEvents\n",
    "    \n",
    "    # Make an array to hold the data (ie the x measurements)\n",
    "    data = []\n",
    "    \n",
    "    # set the random seed.  This will allow us to reproduce the results if we run again\n",
    "    np.random.seed(seed)\n",
    " \n",
    "    # Retrieve nEvents random numbers that will be used to pick which events are signal\n",
    "    # and which are background\n",
    "    n = int(nEvents)\n",
    "    tests = np.random.uniform(0,1,n)\n",
    "    bck = np.random.uniform(0,20,n)\n",
    "    sig = np.random.normal(10,1,n)\n",
    "    \n",
    "    count = 0\n",
    "    for test in tests:\n",
    "        if(test<fSig):\n",
    "            data.append(sig[count])\n",
    "        else:\n",
    "            data.append(bck[count])\n",
    "        count+=1\n",
    "    \n",
    "    # Loop over the events and pick either signal or background and draw from the appropriate \n",
    "    # pdf in each case\n",
    "    \n",
    "    # return the data to the user\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or alternatively using ROOT (do not execute both cells, just either this or the one above depending on what you're planning to use and delete the other from your notebook to avoid mistakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "outputs": [],
   "source": [
    "import ROOT\n",
    "\n",
    "def makeData( SignalToBackground, nSigEvents, seed=12345):\n",
    "    \"\"\"Generates a dataset consisting of nEvents some of which are signal (a Gaussian with a width of 1 centered\n",
    "    at x=5) and the rest of which is background\n",
    "    Definition of SignalToBackground:  The ratio of the number of signal events within 2 sigma of the peak to the number\n",
    "    of background events in that same x-range  (this definition is just a choice)\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "     SignalToBackground : float\n",
    "     Ratio of the number of signal events within 2 sigma of the peak to the number\n",
    "    of background events in that same x-range  (this definition is just a choice) \n",
    "      \n",
    "    nSigEvents : int\n",
    "      total number of signal events generated (NOT the number in +- 2 sigma)\n",
    "      \n",
    "    seed : int\n",
    "      seed for the random number generator\n",
    "      \n",
    "    Returns\n",
    "    =======\n",
    "    data : array\n",
    "      the measurements of x\n",
    "    \"\"\"\n",
    "    fracOutsideTwoSigma = 4.55e-2\n",
    "    # 1-fracOutsideTwoSigma is the fraction of the Signal Events within +-2 sigma\n",
    "    # To get the total number of background events, find the number in +-2 sigma\n",
    "    # which is 4 units of x and then since the background is flat from 0 to 20\n",
    "    # multiply by 20/4=5\n",
    "    \n",
    "    nBackground = 5*nSigEvents*(1-fracOutsideTwoSigma)/SignalToBackground\n",
    "    nEvents = nSigEvents+nBackground\n",
    "    fSig = nSigEvents/nEvents\n",
    "    \n",
    "    # Make an array to hold the data (ie the x measurements)\n",
    "    data = []\n",
    "    \n",
    "    # set the random seed.  This will allow us to reproduce the results if we run again\n",
    "    ROOT.gRandom.SetSeed(seed)\n",
    " \n",
    "    # Retrieve nEvents random numbers that will be used to pick which events are signal\n",
    "    # and which are background\n",
    "    n = int(nEvents)\n",
    "    tests = []\n",
    "    bck = []\n",
    "    sig = []\n",
    "    for i in range(n):\n",
    "        tests.append(ROOT.gRandom.Rndm())\n",
    "        bck.append(ROOT.gRandom.Rndm()*20.0)\n",
    "        sig.append(ROOT.gRandom.Gaus(10, 1))\n",
    "    \n",
    "    # Loop over the events and pick either signal or background and draw from the appropriate \n",
    "    # pdf in each case\n",
    "    count = 0\n",
    "    for test in tests:\n",
    "        if(test<fSig):\n",
    "            data.append(sig[count])\n",
    "        else:\n",
    "            data.append(bck[count])\n",
    "        count+=1\n",
    "        \n",
    "    # return the data to the user\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "source": [
    "Below is a simple test to show you how to use this code.  Remember if you run this code multiple times you should change the seed each time (for example, you could increment the seed each time you call the function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of total data events:  115\n",
      "data:  [11.047401505881462, 11.57102936217666, 10.430661187946646, 0.05376129148641384, 19.7669083856564, 18.106831513232198, 4.15271722392649, 5.849788255848496, 10.40020306144967, 18.038227453213413, 19.672617698234465, 5.150841283081662, 11.287180858495633, 10.579689779144333, 7.887401079055496, 14.621460716891141, 3.221380288584297, 12.013971356671798, 17.317289166065294, 19.67043218407111, 1.5873158075603144, 8.566945494018984, 4.0908571909285545, 9.012729810374696, 10.95527145257708, 1.8665342073964153, 5.937215509613589, 18.55168480304295, 11.380074628603907, 9.148239950472238, 8.762646787312146, 14.837243036840746, 0.9715806568853758, 14.17394790885492, 16.784866956101673, 3.3187576841390776, 15.619958759999147, 5.730732334582038, 6.129395066591146, 13.30522930699366, 2.227843432154315, 9.800887617242747, 17.757135853524453, 13.926225364708127, 8.806557533308181, 8.764287687544494, 15.30192190478613, 11.312840024517657, 1.6980832638363519, 11.653421757228093, 8.53488377794505, 6.7413276689521995, 18.55153159150779, 15.014340006863359, 11.48127650299929, 15.032879775858367, 1.5829792147641042, 17.18778151361223, 16.43008226401116, 18.197433192204176, 2.5726239501876003, 1.6356017418797042, 2.7683114556317956, 7.9875742020560025, 8.486137221619838, 9.416463283292343, 2.444870992650101, 4.027990027627418, 16.232886965680432, 9.359751481134989, 11.218985862132426, 0.14852757089226065, 11.03185451964811, 18.638642961533563, 11.408369146076902, 4.121914548905483, 14.355151245591152, 9.330381400130241, 11.264625286968007, 0.5863944578754254, 12.718007187027123, 0.64395869875848, 14.89561310283532, 9.458260044769101, 2.4350871094610738, 10.85271851577012, 1.335488864500094, 9.317461845796695, 19.92172654735651, 15.387946741479245, 11.475482273176489, 2.052705184215917, 13.996681495458294, 13.223357346558622, 0.9819426124555264, 15.845986036891812, 8.076284270302875, 8.517353883998382, 15.76374347202931, 8.231384464176744, 9.620525510103072, 3.6325768534764924, 10.765054845997017, 9.17101116623899, 3.738074978534307, 8.345821218066883, 19.78069014790599, 4.731996234110387, 18.33664665877658, 18.36794935611266, 1.8259268440640364, 9.27305449771032, 11.175910771834607, 6.273379001042549, 0.9467907447547397]\n"
     ]
    }
   ],
   "source": [
    "mydata = []\n",
    "#  make 10 signal events with a signalToBackground of 1 using random seed 123\n",
    "mydata=makeData(1,20,123)\n",
    "print(\"number of total data events: \",len(mydata))\n",
    "print(\"data: \",mydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "source": [
    "Generate a sample of 1000 signal events with signalToBackground=0.5 and make a histogram of your results. Make sure that the number of bins in your histogram is small enough that you have at least 10 entries per bin (so that it is reasonable to do a binned fit to the histogram). To make life a bit easier, here is function you can use to make your histograms.  You are of course free to write your own function and not use this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "outputs": [],
   "source": [
    "#Import the pyplot module of matplotlib as \"plt\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Makes a histogram filled with the random numbers we generate\n",
    "def plot_histogram(samples,xtitle,ytitle, title, nbins, limits):\n",
    "   \n",
    "    #Plot the histogram of the sampled data with nbins and a nice color\n",
    "    n, bins, patches =plt.hist(samples, bins=nbins, range=limits, color=(0,0.7,0.9))  #Set the color using (r,g,b) values or\n",
    "                                                                  #  use a built-in matplotlib color\"\"\" \n",
    "    bincenters = 0.5*(bins[1:]+bins[:-1])\n",
    "    errs = np.sqrt(n)\n",
    "\n",
    "    plt.errorbar(bincenters, n, yerr=errs, fmt='none')\n",
    "    #Add some axis labels and a descriptive title\n",
    "    plt.xlabel(xtitle)\n",
    "    plt.ylabel(ytitle)\n",
    "\n",
    "    #Get rid of the extra white space on the left/right edges (you can delete these two lines without a problem)\n",
    "    xmin, xmax, ymin, ymax = plt.axis()\n",
    "    plt.axis([limits[0],limits[1],ymin,ymax])\n",
    "\n",
    "    #Not necessarily needed in a Jupyter notebook, but it doesn't hurt\n",
    "    plt.show()\n",
    "    return n, bins, patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or alternatively using ROOT as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "outputs": [],
   "source": [
    "#Import the pyplot module of matplotlib as \"plt\"\n",
    "import math\n",
    "\n",
    "\n",
    "#Makes a histogram filled with the random numbers we generate\n",
    "def plot_histogram(samples,xtitle,ytitle, title, nbins, limits):\n",
    "       \n",
    "    #Create the histogram to contain the sampled data with nbins\n",
    "    h_sampled = ROOT.TH1F(\"h_sampled\", \"Sampled data\", nbins, limits[0], limits[1])\n",
    "    #Add some axis labels and a descriptive title\n",
    "    h_sampled.SetXTitle(xtitle)\n",
    "    h_sampled.SetYTitle(ytitle)\n",
    "    #Set a nice color\n",
    "    h_sampled.SetLineColor(ROOT.kBlack)\n",
    "    \n",
    "    #Add data to the histogram\n",
    "    for s in samples:\n",
    "        h_sampled.Fill(s)\n",
    "    \n",
    "    #Draw the histogram\n",
    "    c_sampled = ROOT.TCanvas(\"c_sampled\")\n",
    "    h_sampled.Draw(\"HIST E\") #Draw histogram with error bars following Gaussian statistics\n",
    "    \n",
    "    #Adjust y-axis range\n",
    "    h_sampled.GetYaxis().SetRangeUser(0, h_sampled.GetMaximum()*1.2)\n",
    "    \n",
    "    c_sampled.Draw()\n",
    "    \n",
    "    #return the canvas and histograms if more work is needed\n",
    "    return c_sampled, h_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "source": [
    "Pretend this is real data.  Your goal is to find the best estimate of how many events are in a Gaussian peak with unknown mean and sigma and what the uncertainty on this estimate is.  In your fit, you can make the assumption that the background is flat (a zeroth order polynomial) but that you don't have a prediction for the background rate.  Use your favorite minimization package to fit the data.  Deterimine the best estimate of the number of events in signal and the uncertainty on that estimate.  (remember, that you must let the position and width of the Gaussian and the size of the background vary in your fit).\n",
    "\n",
    "Hint: For examples of how to perform a least squared fit of a function to data see:\n",
    "- https://github.com/berkeley-physics/Python-Tutorials/blob/master/3%20-%20Specific%20topics/Fitting.ipynb\n",
    "- https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html\n",
    "- https://root.cern/doc/master/multifit_8py.html (ROOT, python)\n",
    "- https://root.cern/doc/master/FittingDemo_8C.html (ROOT, more complete example in C++)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "source": [
    "What is the $\\chi^2$ per degree of freedom for your fit?  What does this number tell you about how well your fit describes the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "source": [
    "If a signal of size $N_S^{meas}$ has a fitted uncertainty $\\sigma_S$, the signficance of the measurement is defined to be\n",
    "$$\n",
    "S^{meas} \\equiv \\frac{N_S^{meas}}{\\sigma_S}\n",
    "$$\n",
    "When the size of the data sample is large enough that Gaussian uncertainties are appropriate, a rule of thumb can be used to give a crude estimate of the expected significance $S^{expected}$ of the measurement. This predicted signficance depends on the number of signal events ($N_{S}$) and is the number of background events populating the region **beneath the signal** ($N_B$):\n",
    "$$\n",
    "S^{expected}  \\approx  \\frac{N_S}{N_S+N_B}\n",
    "$$\n",
    "\n",
    "Repeat the above exercise changing both the number of events in your signal and the signalToBackground ratio.  Plot the values of the measured significance  $S^{meas}$ \n",
    "obtained from your fits as a function of $\\frac{N_S}{\\sqrt{N_S+N_B}}$.  How do your results compare to the simple rule of thumb quoted above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Likelihood Fits, Statistical Methods (40 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning objectives\n",
    "In this question you will:\n",
    "\n",
    "- Construct a likelihood function for a probability distribution with one free parameter\n",
    "- Determine the best fit value of the parameter and estimate its uncertainty both by graphing the likelihood function and using a standard minimization package\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "source": [
    "Consider the problem of determining the lifetime of a species of particle that we can stop in our detector by observing its decays. Assume each time a particle stops, we set the stopping time to be $t=0$ and that we only observe decays that occur up to a time $T_{max}$ after the particle stops.  The distribution of measured times therefore follows the form:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "R(t) & =  R_0 e^{-\\Gamma t} & \\qquad \\qquad 0 \\le t \\le T_{max} \\\\\n",
    "     & =  0 &\\qquad \\qquad {\\rm otherwise}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "For this problem, we'll take as the true decay parameter $\\Gamma=2\\ \\mathrm{sec}^{-1}$ and maximum time that we wait for a decay to be $T_{max}=3$ sec. We can imagine doing the experiment over many times (each experiment takes three seconds) to accumulate a lot of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "source": [
    "First, let's generate some fake data. Generate 1000 decay times that follow the formula above.  (Hint:  use numpy.random.exponential or ROOT.gRandom.Exp and reject events with decay times larger than $T_{max}$.  Verify that your event generation looks reasonable by making a histogram of the decay times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "outputs": [],
   "source": [
    "#Write import math\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def makeData( Gamma, Tmax, nDecays ):\n",
    "    \"\"\"Generates a dataset of decay times.  The distribution of events follows an exponential with \n",
    "    decay parameter Gamma, but where the decays are cut-off after time Tmax\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    Gamma : float\n",
    "      decay parameter of the exponential distribution\n",
    "      \n",
    "    Tmax : float\n",
    "      maximum decay time that can be generated in the dataset\n",
    "      \n",
    "    nDecays : int\n",
    "      number of decay times to generate\n",
    "      \n",
    "    Returns\n",
    "    =======\n",
    "    decayTimes : array\n",
    "      nDecays number of decay times generated according to the exponential distribution with decay\n",
    "      parameter gamma and maximum decay time Tmax\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make an array to hold the decay times\n",
    "    decayTimes = [0.0 for i in range(nDecays)]\n",
    "    \n",
    "    '''Your code here'''\n",
    "    \n",
    "    return decayTimes\n",
    "\n",
    "# Run your function and put plotting code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or using ROOT as follows (reminder: do not execute both cells above, just either this or the one above depending on what you're planning to use and delete the other from your notebook to avoid mistakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "outputs": [],
   "source": [
    "#Write import math\n",
    "import ROOT\n",
    "\n",
    "def makeData( Gamma, Tmax, nDecays ):\n",
    "    \"\"\"Generates a dataset of decay times.  The distribution of events follows an exponential with \n",
    "    decay parameter Gamma, but where the decays are cut-off after time Tmax\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    Gamma : float\n",
    "      decay parameter of the exponential distribution\n",
    "      \n",
    "    Tmax : float\n",
    "      maximum decay time that can be generated in the dataset\n",
    "      \n",
    "    nDecays : int\n",
    "      number of decay times to generate\n",
    "      \n",
    "    Returns\n",
    "    =======\n",
    "    decayTimes : array\n",
    "      nDecays number of decay times generated according to the exponential distribution with decay\n",
    "      parameter gamma and maximum decay time Tmax\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make an array to hold the decay times\n",
    "    decayTimes = [0.0 for i in range(nDecays)]\n",
    "    \n",
    "    '''Your code here'''\n",
    "    \n",
    "    return decayTimes\n",
    "\n",
    "# Run your function and put plotting code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "source": [
    "Calculate the negative log-likelihood function, $-\\ln {\\cal L}$, for your data.  Express your likelihood in terms of the free parameters, $\\Gamma$.\n",
    "\n",
    "Hint: your pdf for the expected distribution of decay times $f(t) $ is an exponental that only extends to $t_{max}$ so:\n",
    "$$\n",
    "\\int_0^{t_{max}}f(t)dt = \\int_0^{t_{max}} R_0 e^{-\\Gamma t} dt = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "source": [
    "We will study the simulated data, pretending that we dont know what value of $\\Gamma$ was used to generate it.  We want to find the best estimate of $\\Gamma$ from the data. \n",
    "\n",
    "We saw in class that for high statistics $-2\\ln {\\cal L}$ is  distributed like a $\\chi^2$ distribution and the uncertainty on the estimate of a parameter of the function can be obtained by finding how much the you can change the parameter to increase $-2\\ln {\\cal L}$ by 1. \n",
    "Write code to calculate the negative log-likelihood:\n",
    "$$\n",
    "- 2 \\ln {\\cal L} = -2 \\sum_i \\ln f(\\Gamma, t_i)\n",
    "$$\n",
    "where the $t_i$ are the time values you generated.  Using this code, find the value of $-2\\ln {\\cal L}$ for $\\Gamma - \\Gamma_{true}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "outputs": [],
   "source": [
    "def minusloglikelihoodFn(Gamma, maxT, decayTimes):\n",
    "    \"\"\"calculates the -ln(Likelihood) for the decayTimes for specified values of maxT and Gamma\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    Gamma : float\n",
    "      hypothesis for lifetime\n",
    "      \n",
    "    Tmax : float\n",
    "      maximum time for observation\n",
    "      \n",
    "    nDecays : array\n",
    "      a dataset of decay times generated according to the distribution described above\n",
    "      \n",
    "    Returns\n",
    "    =======\n",
    "    minusLogLikelihood : float\n",
    "      -ln(Likelihood) given the hypothesized Gamma and maxT for the input data\n",
    "    \"\"\"  \n",
    "    minusLogLikelihood = 0.0\n",
    "    \n",
    "    '''Your code here'''\n",
    "\n",
    "    return minusLogLikelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "source": [
    "There are lots of algorithms for finding the  minimum of a non-linear function such as our negative log-likelihood,  but we won't bother to use any of these algorithms for yet.  Instead, we will explore the minimum by inspecting the behavour of the function. Plot the value of $-\\ln {\\cal L}$ you obtain from your simulated data as you vary $\\Gamma$ in the region  of the true answer ($\\Gamma=2$).  How close is the $\\Gamma $ that gives minimum negative log-likelihood  to the true value of $\\Gamma$?  Estimate the uncertainty on your estimate of $\\Gamma$ by finding the values corresponding to an increase of ${\\cal L}$ of 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "outputs": [],
   "source": [
    "ngrid=100 # How many points to scan\n",
    "G = np.arange(1.75,2.25,0.5/ngrid)  #The gamma values to scan\n",
    "LLG = np.zeros(ngrid)               #The likelihood for these values\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or using ROOT as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "outputs": [],
   "source": [
    "ngrid=100 # How many points to scan\n",
    "G_min = 1.75\n",
    "G_max = 2.25\n",
    "G_step = (G_max-G_min)/ngrid\n",
    "\n",
    "G = [] #The gamma values to scan\n",
    "LLG = [0.0 for i in range(ngrid)] #The likelihood for these values\n",
    "for i in range(ngrid):\n",
    "    G.append(G_min + G_step*i) \n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2e. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "source": [
    "To verify your estimate of the uncertainty on the measured value of $\\Gamma$, generate 100 samples each with 1000 events.  Histogram the estimated $\\Gamma$ for these samples and find the rms of the \"measurements.\"  How does this rms compare to your answers above?\n",
    "\n",
    "Note: while minimizing via a scan as above is instructive, here you can also try to use existing minimizers, e.g. scipy.optimize.minimize using the 'BFGS' method or ROOT.Math.Minimizer with e.g. Minuit2  (or just your custom code you wrote above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Accelerator performance (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning objectives\n",
    "In this question you will:\n",
    "\n",
    "- familiarize with differences and design choices for colliders and fixed-target experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicitly derive the expressions for the center-of-mass energy for the collider and fixed target caes not assuming that the masses of the colliding particles are small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answer here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What approximations do you have to make to derive the simpler formulae usually quoted:\n",
    "$$ E_{\\textrm{cm}}^{\\textrm{collider}} = \\sqrt{4E_1E_2},\\quad E_{cm}^{\\textrm{fixded-target}}=\\sqrt{2m_{\\textrm{target}}E_{\\textrm{beam}}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answer here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Babar experiment (which ran at SLAC until Spring 2008) and the upgraded Belle experiment at KEK in Japan study B mesons produced in $\\Upsilon(4S)$ decays through the process $e^+e^− \\to \\Upsilon(4S) \\to BB$.\n",
    "Both accelerators were designed to operate at a center-of-mass energy of $10.56$ GeV (corresponding to the $\\Upsilon(4S)$ mass). Both accelerators are “asymmetric colliders,” where the energies of the $e^+$ and $e^−$ beams are not the same. This asymmetry means that the center-of-mass is boosted along the beam direction and therefore the produced B mesons are moving, making it possible to measure their lifetime by looking at the distance they travel before decaying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) For a boost of $\\beta\\gamma =$ 0.56 along the $e^+$ direction of motion, determine the required energies of the $e^+$ and $e^−$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ii) Determine the average distance between the B production point and its decay point in the LAB. You can find the value of the B meson lifetime on the PDG website, [pdg.lbl.gov](https://pdg.lbl.gov), using the pdgLive tool. The charged and neutral B mesons have almost the same lifetime. Use the $B^0$ lifetime for this problem. Also, note that in the center-of-mass energy of the B-factories is very close to twice the B mass. You may therefore make the approximation that the B mesons are produced at rest in the center-of-mass.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answer here..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
